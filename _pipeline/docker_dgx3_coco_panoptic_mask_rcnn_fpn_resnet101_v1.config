model {
  faster_rcnn {
    number_of_stages: 3
    num_classes: 80
    num_semantic_classes: 134
    image_resizer {
      fixed_shape_resizer {
        height: 768
        width: 768
      }
      #keep_aspect_ratio_resizer {
      #  min_dimension: 600  # 800
      #  max_dimension: 600  #1365
      #}
    }
    first_stage_fpn_min_level: 2
    first_stage_fpn_max_level: 5
    feature_extractor {
      type: "faster_rcnn_resnet101_fpn"
      first_stage_features_stride: 32 #8
      batch_norm_trainable: false
      weight_decay: 0.0
      fpn_min_level: 2
      fpn_max_level: 6
      fpn_residual_depth: 256
      fpn_output_depth: 256
      aspp_depth: 256
    }
    first_stage_anchor_generator {
      multiscale_anchor_generator {
        min_level: 2
        max_level: 6
        anchor_scale: 8
        aspect_ratios: 0.5
        aspect_ratios: 1.0
        aspect_ratios: 2.0
        scales_per_octave: 1
        normalize_coordinates: false
      }
    }
    first_stage_semantic_conv_hyperparams {
      op: CONV
      regularizer {
        l2_regularizer {
          weight: 0.0
        }
      }
      initializer {
        truncated_normal_initializer {
          stddev: 0.01
        }
      }
    }
    first_stage_atrous_rate: 1 #2
    first_stage_box_predictor_conv_hyperparams {
      op: CONV
      regularizer {
        l2_regularizer {
          weight: 0.0
        }
      }
      initializer {
        truncated_normal_initializer {
          stddev: 0.01
        }
      }
    }
    first_stage_box_predictor_depth: 512
    first_stage_nms_score_threshold: 0.0
    first_stage_nms_iou_threshold: 0.7  # FRCNN uses 0.7, MRCNN uses 0.5
    first_stage_max_proposals: 300  # For FPN it is per layer  # 100
    first_stage_localization_loss_weight: 2.0
    first_stage_objectness_loss_weight: 1.0
    first_stage_semantic_loss_weight: 4.0
    first_stage_minibatch_size: 256
    initial_crop_size: 14
    maxpool_kernel_size: 2
    maxpool_stride: 2
    second_stage_box_predictor {
      mask_rcnn_box_predictor {
        backbone: "FPN"
        fc_hyperparams {
          op: FC
          regularizer {
            l2_regularizer {
              weight: 0.0
            }
          }
          initializer {
            variance_scaling_initializer {
              factor: 1.0
              uniform: true
              mode: FAN_AVG
            }
          }
        }
        box_class_num_conv_layers: 1024
        use_dropout: false
        dropout_keep_probability: 1.0
        conv_hyperparams {
          op: CONV
          regularizer {
            l2_regularizer {
              weight: 0.0
            }
          }
          initializer {
            truncated_normal_initializer {
              stddev: 0.01
            }
          }
        }
        predict_instance_masks: true
        mask_prediction_conv_depth: 512
        mask_height: 33
        mask_width: 33
        mask_prediction_num_conv_layers: 4
      }
    }
    second_stage_post_processing {
      batch_non_max_suppression {
        score_threshold: 0.0
        iou_threshold: 0.6
        max_detections_per_class: 100
        max_total_detections: 300
      }
      score_converter: SOFTMAX
    }
    second_stage_localization_loss_weight: 2.0
    second_stage_classification_loss_weight: 1.0
    second_stage_mask_prediction_loss_weight: 4.0
    second_stage_batch_size: 512
  }
}
train_config {
  # Effective batch size to use for training.
  # For TPU (or sync SGD jobs), the batch size per core (or GPU) is going to be
  # `batch_size` / number of cores (or `batch_size` / number of GPUs).
  batch_size: 3
  # Data augmentation options.
  data_augmentation_options {
    random_horizontal_flip {
    }
  }
  # Whether to synchronize replicas during training.
  sync_replicas: false
  # How frequently to keep checkpoints.
  keep_checkpoint_every_n_hours: 2
  # How frequently to keep summaries in events file.
  save_summaries_secs: 600
  # How frequently to keep checkpoint/model.
  save_interval_secs: 1800
  # Optimizer used to train the DetectionModel.
  optimizer {
    momentum_optimizer {
      #learning_rate {
      #  exponential_decay_learning_rate {
      #    initial_learning_rate: 0.02
      #    decay_steps: 20000
      #    decay_factor: 0.95
      #    staircase: false
      #  }
      #}
      learning_rate: {
        manual_step_learning_rate {
          initial_learning_rate: .0001
          schedule {
            step: 300000
            learning_rate: .0001
          }
          schedule {
            step: 600000
            learning_rate: .00001
          }
        }
      }
      momentum_optimizer_value: 0.9
    }
    use_moving_average: false
  }
  # If greater than 0, clips gradients by this value.
  gradient_clipping_by_norm: 1000.0
  # Checkpoint to restore variables from. Typically used to load feature
  # extractor variables trained outside of object detection.
  fine_tune_checkpoint: "/panoptic/models/pretrained_models/resnet_v1_101_2016_08_28/resnet_v1_101.ckpt"
  # fine_tune_checkpoint: "/panoptic/models/docker_panoptic_mask_rcnn_fpn_resnet101_v1/train_dgx2_1024_01/model.ckpt-432869"
  # fine_tune_checkpoint: "/panoptic/models/docker_panoptic_mask_rcnn_fpn_resnet101_v1/train_dgx2_1024_01/model.ckpt-297768"
  # Type of checkpoint to restore variables from, e.g. 'classification' or
  # 'detection'. Provides extensibility to from_detection_checkpoint.
  # Typically used to load feature extractor variables from trained models.
  fine_tune_checkpoint_type: "classification"
  # fine_tune_checkpoint_type: "detection"
  # Whether to load all checkpoint vars that match model variable names and
  # sizes. This option is only available if `from_detection_checkpoint` is
  # True.
  load_all_detection_checkpoint_vars: false  # false for feature extractor only
  # load_all_detection_checkpoint_vars: true
  # Number of steps to train the DetectionModel for. If 0, will train the model
  # indefinitely.
  num_steps: 1500000
  # Number of training steps between replica startup.
  # This flag must be set to 0 if sync_replicas is set to true.
  startup_delay_steps: 15
#  # If greater than 0, multiplies the gradient of bias variables by this
#  # amount.
#  bias_grad_multiplier: 0
#  # Variables that should not be updated during training.
#  # repeated string freeze_variables = 12;
#  # Number of replicas to aggregate before making parameter updates.
#  replicas_to_aggregate: 1
#  # Maximum number of elements to store within a queue.
#  batch_queue_capacity: 150
#  # Number of threads to use for batching.
#  num_batch_queue_threads: 32
#  # Maximum capacity of the queue used to prefetch assembled batches.
#  prefetch_queue_capacity: 16
#  # If true, boxes with the same coordinates will be merged together.
#  # This is useful when each box can have multiple labels.
#  # Note that only Sigmoid classification losses should be used.
#  merge_multiple_label_boxes: false
#  # If true, will use multiclass scores from object annotations as ground
#  # truth. Currently only compatible with annotated image inputs.
#  use_multiclass_scores: false
#  # Whether to add regularization loss to `total_loss`. This is true by
#  # default and adds all regularization losses defined in the model to
#  # `total_loss`.
#  # Setting this option to false is very useful while debugging the model and
#  # losses.
#  add_regularization_loss: true
#  # Maximum number of boxes used during training.
#  # Set this to at least the maximum amount of boxes in the input data.
#  # Otherwise, it may cause "Data loss: Attempted to pad to a smaller size
#  # than the input element" errors.
#  max_number_of_boxes: 100
#  # Whether to remove padding along `num_boxes` dimension of the groundtruth
#  # tensors.
#  unpad_groundtruth_tensors: true
#  # Whether to retain original images (i.e. not pre-processed) in the tensor
#  # dictionary, so that they can be displayed in Tensorboard. Note that this
#  # will lead to a larger memory footprint.
#  retain_original_images: false
}
train_input_reader {
  # Path to StringIntLabelMap pbtxt file specifying the mapping from string
  # labels to integer ids.
  # label_map_path: "/panoptic/data/mscoco/mscoco_label_map.pbtxt"
  # Whether data should be processed in the order they are read in, or
  # shuffled randomly.
  shuffle: true
  # Buffer size to be used when shuffling.
  shuffle_buffer_size: 2048
  # Buffer size to be used when shuffling file names.
  filenames_shuffle_buffer_size: 500
  # Maximum number of records to keep in reader queue.
#  queue_capacity: 2000
#  # Minimum number of records to keep in reader queue. A large value is needed
#  # to generate a good random shuffle.
#  min_after_dequeue: 1000
#  # The number of times a data source is read. If set to zero, the data source
#  # will be reused indefinitely.
#  num_epochs: 10
#  # Number of reader instances to create.
#  num_readers: 4
#  # Number of records to read from each reader at once.
#  read_block_length: 32
#  # Number of decoded records to prefetch before batching.
#  prefetch_size: 64
#  # Number of parallel decode ops to apply.
#  num_parallel_map_calls: 64
#  # Number of groundtruth keypoints per object.
#  num_keypoints: 0
#  # Whether to load groundtruth instance masks.
  load_instance_masks: true
  # Type of instance mask.
  mask_type: PNG_MASKS
  # Input reader
  tf_record_input_reader {
    input_path: "/panoptic/data/mscoco/train*.tfrecord"
  }
}
eval_config {
  # Number of visualization images to generate.
  num_visualizations: 20
  # Number of examples to process of evaluation.
  num_examples: 5000  # 5000
  # How often to run evaluation.
  eval_interval_secs: 7200
  # Maximum number of times to run evaluation. If set to 0, will run forever.
  max_evals: 1
  # Whether the TensorFlow graph used for evaluation should be saved to disk.
  save_graph: false
  # Path to directory to store visualizations in. If empty, visualization
  # images are not exported (only shown on Tensorboard).
  visualization_export_dir: ""
  # BNS name of the TensorFlow master.
  eval_master: ""
  # Type of metrics to use for evaluation.
  metrics_set: "panoptic_metrics"
  metrics_set: "segmentation_metrics"
  metrics_set: "coco_detection_metrics"
  metrics_set: "coco_mask_metrics"
  # Path to export detections to COCO compatible JSON format.
  export_path: "/panoptic/models/docker_panoptic_mask_rcnn_fpn_resnet101_v1/eval_dgx2_1024"
  # Option to not read groundtruth labels and only export detections to
  # COCO-compatible JSON file.
  ignore_groundtruth: false
  # Use exponential moving averages of variables for evaluation.
  # TODO(rathodv): When this is false make sure the model is constructed
  # without moving averages in restore_fn.
  use_moving_averages: false
  # Whether to evaluate instance masks.
  # Note that since there is no evaluation code currently for instance
  # segmenation this option is unused.
  eval_instance_masks: false
  # Minimum score threshold for a detected object box to be visualized
  min_score_threshold: 0.5
  # Maximum number of detections to visualize
  max_num_boxes_to_visualize: 100
  # When drawing a single detection, each label is by default visualized as
  # <label name> : <label score>. One can skip the name or/and score using the
  # following fields:
  skip_scores: false
  skip_labels: false
  # Whether to show groundtruth boxes in addition to detected boxes in
  # visualizations.
  visualize_groundtruth_boxes: false
  # Box color for visualizing groundtruth boxes.
  groundtruth_box_visualization_color: "black"
  # Whether to keep image identifier in filename when exported to
  # visualization_export_dir.
  keep_image_id_for_visualization_export: false
  # Whether to retain original images (i.e. not pre-processed) in the tensor
  # dictionary, so that they can be displayed in Tensorboard.
  retain_original_images: true
  # If True, additionally include per-category metrics.
  include_metrics_per_category: false  # It is not available in code.
}
eval_input_reader {
  # Path to StringIntLabelMap pbtxt file specifying the mapping from string
  # labels to integer ids.
  # label_map_path: "/panoptic/data/mscoco/mscoco_label_map.pbtxt"
  # Whether data should be processed in the order they are read in, or
  # shuffled randomly.
  shuffle: false
  # Buffer size to be used when shuffling.
  shuffle_buffer_size: 2048
  # Buffer size to be used when shuffling file names.
  filenames_shuffle_buffer_size: 100
  # Maximum number of records to keep in reader queue.
  queue_capacity: 2000
  # Minimum number of records to keep in reader queue. A large value is needed
  # to generate a good random shuffle.
  min_after_dequeue: 1000
  # The number of times a data source is read. If set to zero, the data source
  # will be reused indefinitely.
  num_epochs: 1
  # Number of reader instances to create.
  num_readers: 1
  # Number of records to read from each reader at once.
  read_block_length: 32
  # Number of decoded records to prefetch before batching.
  prefetch_size: 64
  # Number of parallel decode ops to apply.
  num_parallel_map_calls: 64
  # Number of groundtruth keypoints per object.
  num_keypoints: 0
  # Whether to load groundtruth instance masks.
  load_instance_masks: true
  # Type of instance mask.
  mask_type: PNG_MASKS
  # Input reader
  tf_record_input_reader {
    input_path: "/panoptic/data/mscoco/val*.tfrecord"
  }
}
