model {
  mt {
    instance_segmentation: False
    num_classes: 9
    num_semantic_classes: 20
    train_image_resizer {
      fixed_shape_resizer {
        height: 960
        width: 960
      }
    }
    eval_image_resizer {
      fixed_shape_resizer {
        height: 1024
        width: 2048
      }
    }
    feature_extractor {
      type: "mt_resnet50_beta"
      first_stage_features_stride: 16 #8
      batch_norm{
        decay: 0.95
        center: true
        scale: true
        epsilon: 0.00001
        train: true
        fused: true
      }
      # For l2 regularizer
      weight_decay: 0.0001
      aspp_depth: 256
      decoder_conv_hyperparams {
        op: CONV
        regularizer {
          l2_regularizer {
            weight: 0.00001
          }
        }
        initializer {
          variance_scaling_initializer {
          }
        }
        batch_norm {
          decay: 0.9997
          center: true
          scale: true
          epsilon: 0.00001
          train: true
          fused: true
        }
      }
    }
    semantic_loss_weight: 2.0
    instance_loss_weight: 1.0
    aspp_conv_hyperparams {
        op: CONV
        regularizer {
          l2_regularizer {
            weight: 0.00001
          }
        }
        initializer {
          variance_scaling_initializer {
          }
        }
        batch_norm {
          decay: 0.9997
          center: true
          scale: true
          epsilon: 0.00001
          train: true
          fused: true
        }
    }
    refinement_conv_hyperparams {
        op: CONV
        regularizer {
          l2_regularizer {
            weight: 0.00001
          }
        }
        initializer {
          variance_scaling_initializer {
          }
        }
        batch_norm {
          decay: 0.9997
          center: true
          scale: true
          epsilon: 0.00001
          train: false
          fused: true
        }
    }
  }
}
train_config {
  batch_size: 8
  # Data augmentation options.
  data_augmentation_options {
    random_horizontal_flip {
    }
  }
  data_augmentation_options {
    random_crop_image {
      min_object_covered: 0.0
      min_aspect_ratio: 0.75
      max_aspect_ratio: 1.33
      min_area: 0.1
      max_area: 1.0
      overlap_thresh: 0.3
      random_coef: 0.0
    }
  }
  #data_augmentation_options {
  #  random_image_scale {
  #    min_scale_ratio: 0.5
  #    max_scale_ratio: 2.0
  #  }
  #}
  #data_augmentation_options {
  #  random_crop_to_aspect_ratio {
  #    aspect_ratio: 1.0
  #    overlap_thresh: 0.3
  #  }
  #}
  # Optimizer used to train the DetectionModel.
  optimizer {
    momentum_optimizer {
      learning_rate {
        polynomial_decay_learning_rate {
          initial_learning_rate: 0.01
          decay_steps: 90000
          decay_factor: 0.9
          cycle: false
        }
      }
      #learning_rate {
      #  exponential_decay_learning_rate {
      #    initial_learning_rate: 0.01
      #    decay_steps: 2000
      #    decay_factor: 0.9
      #    staircase: false
      #  }
      #}
      #learning_rate: {
      #  manual_step_learning_rate {
      #    initial_learning_rate: .0001
      #    schedule {
      #      step: 300000
      #      learning_rate: .00001
      #    }
      #    schedule {
      #      step: 600000
      #      learning_rate: .000001
      #    }
      #  }
      #}
      momentum_optimizer_value: 0.9
    }
    use_moving_average: false
  }
  gradient_clipping_by_norm: 200.0
  # fine_tune_checkpoint: "/remote/00_ImageNetPretrainedModels/resnet_v1_50_2016_08_28/resnet_v1_50.ckpt"
  fine_tune_checkpoint: "/remote/00_ImageNetPretrainedModels/resnet_v1_50_2018_05_04/resnet_v1_50_beta.ckpt"
  # Type of checkpoint to restore variables from, e.g. 'classification' or
  # 'detection'. Provides extensibility to from_detection_checkpoint.
  # Typically used to load feature extractor variables from trained models.
  fine_tune_checkpoint_type: "classification"
  # fine_tune_checkpoint_type: "detection"
  # Whether to load all checkpoint vars that match model variable names and
  # sizes. This option is only available if `from_detection_checkpoint` is
  # True.
  load_all_detection_checkpoint_vars: false  # false for feature extractor only
  # load_all_detection_checkpoint_vars: true
}
train_input_reader {
  shuffle: true
  # Buffer size to be used when shuffling.
  shuffle_buffer_size: 2048
  # Buffer size to be used when shuffling file names.
  filenames_shuffle_buffer_size: 500
  # Whether to load groundtruth instance masks.
  load_instance_masks: true
  # Type of instance mask.
  mask_type: PNG_MASKS
  # Input reader
  tf_record_input_reader {
    input_path: "/remote/02_Cityscapes/data/tf_records_full/train*.tfrecord"
  }
  # -1 allows autotune or set to the same as batch size
  num_prefetch_batches: 8
  # batch_size * num_parallel_batches = cores available
  num_parallel_batches: 2
}
eval_config {
  # Whether the TensorFlow graph used for evaluation should be saved to disk.
  save_graph: false
  # Path to directory to store visualizations in. If empty, visualization
  # images are not exported (only shown on Tensorboard).
  visualization_export_dir: ""
  # Type of metrics to use for evaluation.
  # metrics_set: "panoptic_metrics"
  # metrics_set: "segmentation_metrics"
  metrics_set: "cityscapes_iou_metrics"
  # metrics_set: "cityscapes_ap_metrics"
  # metrics_set: "coco_detection_metrics"
  # metrics_set: "coco_mask_metrics"
  # Path to export detections to COCO compatible JSON format.
  # export_path: "/panoptic/models/docker_panoptic_mask_rcnn_fpn_resnet101_v1/eval_dgx2_1024"
  # Option to not read groundtruth labels and only export detections to
  # COCO-compatible JSON file.
  ignore_groundtruth: false
}
eval_input_reader {
  shuffle: true
  # Whether to load groundtruth instance masks.
  load_instance_masks: true
  # Type of instance mask.
  mask_type: PNG_MASKS
  # Input reader
  tf_record_input_reader {
    input_path: "/remote/02_Cityscapes/data/tf_records_full/val*.tfrecord"
  }
  # -1 allows autotune
  num_prefetch_batches: 1
  num_parallel_batches: 1
}
